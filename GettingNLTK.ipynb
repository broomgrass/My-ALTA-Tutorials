{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "poeUrl = \"http://www.gutenberg.org/files/2147/2147-0.txt\"\n",
    "poeString = urllib.request.urlopen(poeUrl).read().decode().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# isolate The Gold Bug\n",
    "start = poeString.find(\"THE GOLD-BUG\")\n",
    "end = poeString.find(\"FOUR BEASTS IN ONE\")\n",
    "goldBugString = poeString[start:end]\n",
    "# save the file locally\n",
    "directory = \"data\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "with open(\"data/goldBug.txt\", \"w\") as f:\n",
    "    f.write(goldBugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/goldBug.txt\", \"r\") as f:\n",
    "    goldBugString = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'goldBugString' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dc81a920bbea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgoldBugTokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoldBugString\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgoldBugTokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'goldBugString' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "goldBugTokens = nltk.word_tokenize(goldBugString)\n",
    "goldBugTokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE', 'GOLD-BUG', 'What', 'ho', '!', 'what', 'ho', '!', 'this', 'fellow'] (for loop technique\n",
      "['THE', 'GOLD-BUG', 'What', 'ho', '!', 'what', 'ho', '!', 'this', 'fellow'] (list comprehension technique)\n"
     ]
    }
   ],
   "source": [
    "#  technique 1 where we create a new list\n",
    "loopList = []\n",
    "for word in goldBugTokens[:10]:\n",
    "    loopList.append(word)\n",
    "print(loopList, \"(for loop technique\")\n",
    "    \n",
    "    \n",
    "# technique 2 with list comprehension\n",
    "print([word for word in goldBugTokens[:10]], \"(list comprehension technique)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THE', 'GOLD-BUG', 'What', 'ho', 'what', 'ho', 'this', 'fellow']\n"
     ]
    }
   ],
   "source": [
    "print([word for word in goldBugTokens[:10] if word[0].isalpha()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'GOLD-BUG': 1,\n",
       "         'THE': 1,\n",
       "         'What': 1,\n",
       "         'fellow': 1,\n",
       "         'ho': 2,\n",
       "         'this': 1,\n",
       "         'what': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goldBugRealWordTokensSample = [word for word in goldBugTokens[:10] if word[0].isalpha()]\n",
    "goldBugRealWordFrequenciesSample = nltk.FreqDist(goldBugRealWordTokensSample)\n",
    "goldBugRealWordFrequenciesSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ho What fellow this GOLD-BUG what  THE \n",
      "   2    1    1    1    1    1    1 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealWordFrequenciesSample.tabulate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ho what this fellow gold-bug  the \n",
      "   2    2    1    1    1    1 \n"
     ]
    }
   ],
   "source": [
    "goldBugTokensLowercase = nltk.word_tokenize(goldBugString.lower()) # use lower() to convert entire string to lowercase\n",
    "goldBugRealWordTokensLowercaseSample = [word for word in goldBugTokensLowercase[:10] if word[0].isalpha()]\n",
    "goldBugRealWordFrequenciesSample = nltk.FreqDist(goldBugRealWordTokensLowercaseSample)\n",
    "goldBugRealWordFrequenciesSample.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goldBugTokensLowercase = nltk.word_tokenize(goldBugString.lower())\n",
    "goldBugRealWordTokensLowercase = [word for word in goldBugTokensLowercase if word[0].isalpha()]\n",
    "goldBugRealWordFrequencies = nltk.FreqDist(goldBugRealWordTokensLowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of types:  2681\n",
      "number of tokens:  13508\n",
      "type/token ratio:  0.1984749777909387\n"
     ]
    }
   ],
   "source": [
    "print(\"number of types: \", len(goldBugRealWordFrequencies))\n",
    "print(\"number of tokens: \", len(goldBugRealWordTokensLowercase))\n",
    "print(\"type/token ratio: \", len(goldBugRealWordFrequencies)/len(goldBugRealWordTokensLowercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the   of  and    i   to    a   in   it  you  was that with   as  for  had   at   he this  but   we \n",
      " 877  465  359  336  329  327  238  213  162  137  130  114  113  113  110  108  103   99   99   98 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealWordFrequencies.tabulate(20) # show a sample of the top frequency terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'did', 'do', 'does', 'doing', 'don', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'it', 'its', 'itself', 'just', 'me', 'more', 'most', 'my', 'myself', 'no', 'nor', 'not', 'now', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 's', 'same', 'she', 'should', 'so', 'some', 'such', 't', 'than', 'that', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', 'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "print(sorted(stopwords)) # sort them alphabetically before printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample words: ['the', 'gold-bug', 'what', 'ho', 'what', 'ho', 'this', 'fellow']\n",
      "sample words not in stopwordslist:  ['gold-bug', 'ho', 'ho', 'fellow']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample words:\", goldBugRealWordTokensLowercaseSample)\n",
    "print(\"sample words not in stopwordslist: \", [word for word in goldBugRealWordTokensLowercaseSample if not word in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first filter tokens with alphabetic characters\n",
    "gbWords = [word for word in goldBugTokensLowercase if word[0].isalpha()]\n",
    "# then filter stopwords\n",
    "gbContentWords = [word for word in gbWords if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upon   de jupiter legrand  one said well massa could  bug skull parchment tree made first time much   us  two  dat \n",
      "  81   73   53   47   38   35   35   34   33   32   29   27   25   25   24   24   23   23   23   22 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealContentWordTokensLowercase = [word for word in goldBugTokensLowercase \\\n",
    "        if word[0].isalpha() and word not in stopwords]\n",
    "goldBugRealContentWordFrequencies = nltk.FreqDist(goldBugRealContentWordTokensLowercase)\n",
    "goldBugRealContentWordFrequencies.tabulate(20) # show a sample of the top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 73 matches:\n",
      "ou , '' here interrupted Jupiter ; `` de bug is a goole bug , solid , ebery bi\n",
      "is your master ? '' `` Why , to speak de troof , massa , him not so berry well\n",
      " aint find nowhar -- dat 's just whar de shoe pinch -- my mind is got to be be\n",
      "taint worf while for to git mad about de matter -- Massa Will say noffin at al\n",
      " -- Massa Will say noffin at all aint de matter wid him -- but den what make h\n",
      "a gose ? And den he keep a syphon all de time -- '' '' Keeps a what , Jupiter \n",
      " , Jupiter ? '' `` Keeps a syphon wid de figgurs on de slate -- de queerest fi\n",
      "' `` Keeps a syphon wid de figgurs on de slate -- de queerest figgurs I ebber \n",
      " syphon wid de figgurs on de slate -- de queerest figgurs I ebber did see . Is\n",
      "vers . Todder day he gib me slip fore de sun up and was gone de whole ob de bl\n"
     ]
    }
   ],
   "source": [
    "goldBugText = nltk.Text(goldBugTokens)\n",
    "goldBugText.concordance(\"de\", lines=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show a table of the top 20 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upon   de jupiter legrand  one said well massa could  bug skull parchment tree made first time much   us  two  dat \n",
      "  81   73   53   47   38   35   35   34   33   32   29   27   25   25   24   24   23   23   23   22 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealContentWordTokensLowercase = [word for word in goldBugTokensLowercase \\\n",
    "        if word[0].isalpha() and word not in stopwords]\n",
    "goldBugRealContentWordFrequencies = nltk.FreqDist(goldBugRealContentWordTokensLowercase)\n",
    "goldBugRealContentWordFrequencies.tabulate(20) # show a sample of the top "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose 3 words to add to the stopwords list using list concatenation - good words to add seem like upon, de, and us (though us would, of course, be useful in my own research. But for the sake of this experiment...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how to do this? I have the \"stopwords\" variable. Maybe I can use the append function somehow? It doesn't seem to be advised on Google, though. Buuut..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords.append(\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upon jupiter legrand  one said well massa could  bug skull parchment tree made first time much   us  two  dat would \n",
      "  81   53   47   38   35   35   34   33   32   29   27   25   25   24   24   23   23   23   22   22 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealContentWordTokensLowercase = [word for word in goldBugTokensLowercase \\\n",
    "        if word[0].isalpha() and word not in stopwords]\n",
    "goldBugRealContentWordFrequencies = nltk.FreqDist(goldBugRealContentWordTokensLowercase)\n",
    "goldBugRealContentWordFrequencies.tabulate(20) # show a sample of the top "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that worked, but it only works for one word at a time (from what I can figure out) and there has to be a better way to do it. Somehow, I want to make another list and then combine it with the stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwordsAdd = [\"de\", \"upon\", \"us\"] # well, that was easier than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'upon', 'us']\n"
     ]
    }
   ],
   "source": [
    "print(stopwordsAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwordsMod = stopwords + stopwordsAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupiter legrand  one said well massa could  bug skull parchment tree made first time much  two  dat would beetle  way \n",
      "  53   47   38   35   35   34   33   32   29   27   25   25   24   24   23   23   22   22   22   21 \n"
     ]
    }
   ],
   "source": [
    "goldBugRealContentWordTokensLowercase = [word for word in goldBugTokensLowercase \\\n",
    "        if word[0].isalpha() and word not in stopwordsMod]\n",
    "goldBugRealContentWordFrequencies = nltk.FreqDist(goldBugRealContentWordTokensLowercase)\n",
    "goldBugRealContentWordFrequencies.tabulate(20) # aaaawwww yeaaaaah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hindsight, I probably could have just done stopwords +=stopwordsAdd. Noted for future!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of testing for presence in the stopword list, how would test for words that contain 10 characters or more? For this question, I ~think~ I want to make a list of words more than ten, then test against goldBugRealContentWordTokensLowercase. I think I can use a combination of token length and conditional statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goldBugTenChars = [word for word in goldBugTokensLowercase \\\n",
    "        if len(word)>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['misfortunes', 'mortification', 'forefathers', 'perceptible', 'undergrowth', 'horticulturists', 'impenetrable', 'acquaintance', 'misanthropy', 'entomological', 'swammerdamm', 'accompanied', 'supervision', 'guardianship', 'hickory-nut', 'interrupted', 'newfoundland', 'contemplating', \"death's-head\", 'observation', \"death's-head\", 'superstition', 'unaccountably', 'resemblance', \"death's-head\", 'excessively', 'examination', 'writing-desk', 'disappeared', 'supposition', 'circumstance', '_brusquerie_', 'satisfaction', 'expectation', 'empressement', 'strengthened', 'entertained', 'countenance', 'ghastliness', 'seriousness', 'inexpressibly', 'possessions', 'naturalists', 'exceedingly', 'consideration', 'concordance', 'grandiloquent', 'examination', 'interrupting', 'precautions', 'immediately', 'satisfaction', 'accompanied', 'complaisance', 'conversation', 'northwesterly', 'excessively', 'contrivance', 'inaccessible', 'interspersed', 'precipitating', 'maintaining', 'circumstances', 'liriodendron', 'magnificent', 'projections', 'accomplished', 'achievement', 'entertained', 'alternative', 'opportunity', 'lor-gol-a-marcy', 'sarcumstance', 'left-handed', 'immediately', 'accomplished', 'established', 'disposition', 'circumstances', 'innumerable', 'superstitions', 'confirmation', 'maintaining', 'suggestions', 'preconceived', 'demonstration', 'entertained', 'picturesque', 'whereabouts', 'embarrassment', 'proceedings', 'obstreperous', 'apprehension', 'interruption', 'effectually', 'deliberation', 'disconcerted', 'thoughtfully', 'recommenced', 'gold-seeker', 'disappointment', 'reluctantly', 'prevarication', 'pertinacity', 'vociferated', 'astonishment', 'indications', 'understanding', 'unaccountably', 'extravagant', 'forethought', 'deliberation', 'expectation', 'unfortunate', 'interrupted', 'playfulness', 'frantically', 'intermingled', 'countenance', 'disappointment', 'preservation', 'mineralizing', 'bi-chloride', 'trelliswork', 'impossibility', 'incalculable', 'predominant', 'countenance', 'thunderstricken', 'deliberation', 'immediately', 'immediately', 'examination', 'arrangement', 'promiscuously', 'inscriptions', 'exceedingly', 'identification', 'eighty-three', 'vine-leaves', 'bacchanalian', 'sword-handles', 'exquisitely', 'avoirdupois', 'ninety-seven', 'undervalued', 'examination', 'extraordinary', 'circumstances', \"death's-head\", 'astonishment', \"death's-head\", 'coincidence', 'immediately', 'singularity', 'coincidence', 'coincidences', 'coincidence', 'recollected', 'glow-worm-like', 'magnificent', 'demonstration', 'investigation', 'resemblance', 'enthusiastic', 'circumstances', 'established', \"death's-head\", 'engagements', 'imperishable', \"death's-head\", 'comparatively', 'nevertheless', 'reflections', 'distinctness', 'newfoundland', 'examination', 'particulars', 'preparations', 're-application', 'scrutinized', \"death's-head\", 'immediately', 'strengthening', 'persevering', \"death's-head\", 'hieroglyphical', \"death's-head\", 'irresistibly', 'presentiment', 'coincidences', 'extraordinary', 'sufficiently', 'intervention', \"death's-head\", 'circumstance', 'money-seekers', 'money-finders', 'accumulations', 'inexpressible', \"death's-head\", '485â€ 528806*81', 'constructing', 'cryptographs', 'abstruseness', 'circumstances', 'application', 'established', 'alternative', 'probabilities', 'appreciable', 'consideration', 'cryptograph', 'comparatively', 'predominant', 'constructed', 'predominates', 'predominant', 'supposition', 'cryptograph', 'repetitions', 'collocation', 'repetitions', 'arrangements', 'established', 'commencements', 'terminations', 'combination', 'immediately', 'commencement', 'represented', 'juxtaposition', 'combination', '_termination_', 'immediately', 'arrangement', 'substituting', 'represented', 'combinations', 'arrangement', 'represented', 'combination', 'translating', 'representing', 'arrangement', 'immediately', 'represented', 'cryptograph', 'combination', 'translating', 'represented', 'unnecessary', 'development', 'cryptograph', 'translation', \"death's-head\", 'cryptographist', 'composition', 'exceedingly', \"death's-head\", 'neighborhood', 'information', 'manor-house', 'accordingly', 're-instituted', 'resemblance', 'hollow-backed', 'discoveries', 'preconceived', 'established', 'pocket-compass', 'distinguish', 'interpretation', 'exceedingly', 'abstraction', 'establishment', 'deep-seated', 'impressions', 'grandiloquence', 'excessively', 'mystification', 'observation', 'participants']\n"
     ]
    }
   ],
   "source": [
    "# I actually didn't need to do as much as I thought!\n",
    "# to double check and make sure that it did, indeed, work ---\n",
    "print(goldBugTenChars) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Question! determine whether or not the word provided to the concordance function is case sensitive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 73 matches:\n",
      "ou , '' here interrupted Jupiter ; `` de bug is a goole bug , solid , ebery bi\n",
      "is your master ? '' `` Why , to speak de troof , massa , him not so berry well\n",
      " aint find nowhar -- dat 's just whar de shoe pinch -- my mind is got to be be\n",
      "taint worf while for to git mad about de matter -- Massa Will say noffin at al\n",
      " -- Massa Will say noffin at all aint de matter wid him -- but den what make h\n",
      "a gose ? And den he keep a syphon all de time -- '' '' Keeps a what , Jupiter \n",
      " , Jupiter ? '' `` Keeps a syphon wid de figgurs on de slate -- de queerest fi\n",
      "' `` Keeps a syphon wid de figgurs on de slate -- de queerest figgurs I ebber \n",
      " syphon wid de figgurs on de slate -- de queerest figgurs I ebber did see . Is\n",
      "vers . Todder day he gib me slip fore de sun up and was gone de whole ob de bl\n"
     ]
    }
   ],
   "source": [
    "# I think I can just use the original code for the concordance lesson, \n",
    "# but use \"DE\" instead of \"de\".\n",
    "goldBugText.concordance(\"DE\", lines=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, no case sensitivity here! On to the next lesson!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
